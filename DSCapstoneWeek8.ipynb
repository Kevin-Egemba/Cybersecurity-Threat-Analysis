{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " UNSW-NB15 Training loaded successfully! Shape: (175341, 45)\n",
      " UNSW-NB15 Testing loaded successfully! Shape: (82332, 45)\n",
      " BETH Training loaded successfully! Shape: (763144, 16)\n",
      " BETH Testing loaded successfully! Shape: (188967, 16)\n",
      " Cybersecurity Attacks loaded successfully! Shape: (40000, 25)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import platform\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Detect operating system and set base paths\n",
    "if platform.system() == \"Windows\":\n",
    "    base_unsw = Path(r\"C:\\Users\\kegem\\OneDrive\\Datascience Masters\\DS Summer 2025 SEMESTER 3\\DX799S O1 Data Science Capstone (Summer 1 2025)\\Network Security DataSet\\CSV Files\\Training and Testing Sets\")\n",
    "    base_beth = Path(r\"C:\\Users\\kegem\\OneDrive\\Datascience Masters\\DS Summer 2025 SEMESTER 3\\DX799S O1 Data Science Capstone (Summer 1 2025)\\Beth DataSet\")\n",
    "    base_cyber = Path(r\"C:\\Users\\kegem\\OneDrive\\Datascience Masters\\DS Summer 2025 SEMESTER 3\\DX799S O1 Data Science Capstone (Summer 1 2025)\\Cybersecurity Attacks DataSets\")\n",
    "else:\n",
    "    base_unsw = Path(\"/Users/kevinegemba/Library/CloudStorage/OneDrive-Personal/Datascience Masters/DS Summer 2025 SEMESTER 3/DX799S O1 Data Science Capstone (Summer 1 2025)/Network Security DataSet/CSV Files/Training and Testing Sets\")\n",
    "    base_beth = Path(\"/Users/kevinegemba/Library/CloudStorage/OneDrive-Personal/Datascience Masters/DS Summer 2025 SEMESTER 3/DX799S O1 Data Science Capstone (Summer 1 2025)/Beth DataSet\")\n",
    "    base_cyber = Path(\"/Users/kevinegemba/Library/CloudStorage/OneDrive-Personal/Datascience Masters/DS Summer 2025 SEMESTER 3/DX799S O1 Data Science Capstone (Summer 1 2025)/Cybersecurity Attacks DataSets\")\n",
    "\n",
    "# File paths\n",
    "unsw_train_set = base_unsw / \"UNSW_NB15_training-set.csv\"\n",
    "unsw_test_set = base_unsw / \"UNSW_NB15_testing-set.csv\"\n",
    "beth_train_set = base_beth / \"labelled_training_data.csv\"\n",
    "beth_test_set = base_beth / \"labelled_testing_data.csv\"\n",
    "cyber_attack_set = base_cyber / \"cybersecurity_attacks.csv\"\n",
    "\n",
    "# Load and test\n",
    "datasets = {\n",
    "    \"UNSW-NB15 Training\": unsw_train_set,\n",
    "    \"UNSW-NB15 Testing\": unsw_test_set,\n",
    "    \"BETH Training\": beth_train_set,\n",
    "    \"BETH Testing\": beth_test_set,\n",
    "    \"Cybersecurity Attacks\": cyber_attack_set\n",
    "}\n",
    "\n",
    "for name, path in datasets.items():\n",
    "    try:\n",
    "        df = pd.read_csv(path)\n",
    "        print(f\" {name} loaded successfully! Shape: {df.shape}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\" {name} - File not found. Check the path: {path}\")\n",
    "    except Exception as e:\n",
    "        print(f\" {name} - An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Timestamp', 'Source IP Address', 'Destination IP Address', 'Source Port', 'Destination Port', 'Protocol', 'Packet Length', 'Packet Type', 'Traffic Type', 'Payload Data', 'Malware Indicators', 'Anomaly Scores', 'Alerts/Warnings', 'Attack Type', 'Attack Signature', 'Action Taken', 'Severity Level', 'User Information', 'Device Information', 'Network Segment', 'Geo-location Data', 'Proxy Information', 'Firewall Logs', 'IDS/IPS Alerts', 'Log Source']\n"
     ]
    }
   ],
   "source": [
    "# Load the Cybersecurity Attacks dataset\n",
    "cybersecurity_attacks = pd.read_csv(cyber_attack_set)\n",
    "\n",
    "# Display the actual column names\n",
    "print(cybersecurity_attacks.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KNN on Cybersecurity Attacks Dataset\n",
      "Dropping non-numeric columns: ['Timestamp', 'Source IP Address', 'Destination IP Address', 'Protocol', 'Packet Type', 'Traffic Type', 'Payload Data', 'Malware Indicators', 'Alerts/Warnings', 'Attack Type', 'Attack Signature', 'Action Taken', 'Severity Level', 'User Information', 'Device Information', 'Network Segment', 'Geo-location Data', 'Proxy Information', 'Firewall Logs', 'IDS/IPS Alerts', 'Log Source']\n",
      "[[1874 1247  875]\n",
      " [1855 1340  853]\n",
      " [1854 1290  812]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        DDoS       0.34      0.47      0.39      3996\n",
      "   Intrusion       0.35      0.33      0.34      4048\n",
      "     Malware       0.32      0.21      0.25      3956\n",
      "\n",
      "    accuracy                           0.34     12000\n",
      "   macro avg       0.33      0.34      0.33     12000\n",
      "weighted avg       0.33      0.34      0.33     12000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cybersecurity Attacks Dataset\n",
    "\n",
    "print(\"\\nKNN on Cybersecurity Attacks Dataset\")\n",
    "cyber_df = pd.read_csv(cyber_attack_set)\n",
    "cyber_df.drop(columns=['Flow ID', 'Timestamp'], errors='ignore', inplace=True)\n",
    "cyber_df.dropna(inplace=True)\n",
    "\n",
    "#Drop non-numeric columns (e.g., timestamps, IPs, strings)\n",
    "non_numeric_cols = cybersecurity_attacks.select_dtypes(include=['object']).columns\n",
    "print(\"Dropping non-numeric columns:\", non_numeric_cols.tolist())\n",
    "X_cyber = cybersecurity_attacks.drop(columns=['Attack Type'] + non_numeric_cols.tolist(), errors='ignore')\n",
    "\n",
    "# Use Attack Type as the classification target\n",
    "y_cyber = cybersecurity_attacks['Attack Type']\n",
    "\n",
    "# Scale features\n",
    "scaler_cyber = StandardScaler()\n",
    "X_cyber_scaled = scaler_cyber.fit_transform(X_cyber)\n",
    "X_train_cyber, X_test_cyber, y_train_cyber, y_test_cyber = train_test_split(X_cyber_scaled, y_cyber, test_size=0.3, random_state=42)\n",
    "\n",
    "knn_cyber = KNeighborsClassifier(n_neighbors=5, p=2)\n",
    "knn_cyber.fit(X_train_cyber, y_train_cyber)\n",
    "y_pred_cyber = knn_cyber.predict(X_test_cyber)\n",
    "print(confusion_matrix(y_test_cyber, y_pred_cyber))\n",
    "print(classification_report(y_test_cyber, y_pred_cyber))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# KNN Model Results: Cybersecurity Attacks Dataset\n",
    "\n",
    "## Model Overview\n",
    "In this analysis, I applied the **K-Nearest Neighbors (KNN)** classifier to the Cybersecurity Attacks dataset using the Euclidean distance metric (`p=2`) and `k=5`.\n",
    "\n",
    "Before modeling, wI:\n",
    "- Dropped **non-numeric columns** such as IP addresses, protocol names, user and device metadata, and timestamps.\n",
    "- Used **`Attack Type`** (DDoS, Intrusion, Malware) as the **multiclass classification target**.\n",
    "- Scaled all numeric features using `StandardScaler` to ensure that distance-based calculations were not biased by feature scale.\n",
    "\n",
    "\n",
    "## Confusion Matrix\n",
    "\n",
    "[[1874 1247  875]\n",
    "[1855 1340  853]\n",
    "[1854 1290  812]]\n",
    "\n",
    "- Each row represents actual class labels, and each column represents predicted class labels.\n",
    "- For example, 1874 actual DDoS samples were correctly classified, while 1247 were misclassified as Intrusion and 875 as Malware.\n",
    "\n",
    "\n",
    "## Classification Report\n",
    "\n",
    "| Class       | Precision | Recall | F1-Score | Support |\n",
    "|-------------|-----------|--------|----------|---------|\n",
    "| DDoS        | 0.34      | 0.47   | 0.39     | 3996    |\n",
    "| Intrusion   | 0.35      | 0.33   | 0.34     | 4048    |\n",
    "| Malware     | 0.32      | 0.21   | 0.25     | 3956    |\n",
    "| **Accuracy**|           |        | **0.34** | 12000   |\n",
    "\n",
    "- **Macro average F1**: 0.33 — indicates the average F1 across classes, treating each class equally.\n",
    "- **Weighted average F1**: 0.33 — takes into account class support (i.e., number of samples per class).\n",
    "\n",
    "---\n",
    "\n",
    "## Why KNN?\n",
    "\n",
    "- KNN is a **simple, interpretable, and non-parametric model** — it makes no assumptions about the data distribution.\n",
    "- It is effective when **local neighborhoods contain informative structure**.\n",
    "- Useful for datasets where **relationships are not linearly separable** but still cluster in feature space.\n",
    "\n",
    "---\n",
    "\n",
    "## Limitations Observed\n",
    "\n",
    "1. **Low overall accuracy (34%)** and **poor recall for Malware "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evil\n",
      "0    763144\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "beth_all = pd.read_csv(beth_train_set)\n",
    "print(beth_all['evil'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KNN on BETH Dataset (With Balanced Test Set Including Class 1)\n",
      "Test Set Evil Class Distribution:\n",
      " evil\n",
      "0    228944\n",
      "Name: count, dtype: int64\n",
      "[[228944]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    228944\n",
      "\n",
      "    accuracy                           1.00    228944\n",
      "   macro avg       1.00      1.00      1.00    228944\n",
      "weighted avg       1.00      1.00      1.00    228944\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  BETH Dataset (Ensuring Class 1 in Test Set)\n",
    "\n",
    "print(\"\\nKNN on BETH Dataset (With Balanced Test Set Including Class 1)\")\n",
    "\n",
    "# Load dataset\n",
    "beth_df = pd.read_csv(beth_train_set)\n",
    "\n",
    "# Clean and prepare the target variable\n",
    "beth_df['evil'] = pd.to_numeric(beth_df['evil'], errors='coerce')\n",
    "\n",
    "# Drop irrelevant or high-cardinality columns\n",
    "beth_df.drop(columns=['args', 'stackAddresses', 'hostName', 'processName', 'eventName'], errors='ignore', inplace=True)\n",
    "\n",
    "# Drop any rows missing the target\n",
    "beth_df.dropna(subset=['evil'], inplace=True)\n",
    "\n",
    "# Get dummies and ensure proper type for categorical variables\n",
    "beth_df = pd.get_dummies(beth_df, drop_first=True)\n",
    "beth_df = beth_df.astype({col: 'int64' for col in beth_df.select_dtypes('bool').columns})\n",
    "beth_df.dropna(inplace=True)\n",
    "\n",
    "\n",
    "# Manual Stratification to Include Class 1 in Test Set\n",
    "\n",
    "# Separate positive and negative classes\n",
    "beth_0 = beth_df[beth_df['evil'] == 0]\n",
    "beth_1 = beth_df[beth_df['evil'] == 1]\n",
    "\n",
    "# If too few class 1 examples, use them all for test\n",
    "beth_1_test = beth_1\n",
    "beth_0_train, beth_0_test = train_test_split(beth_0, test_size=0.3, random_state=42)\n",
    "\n",
    "# Combine class 0 + class 1 into train/test sets\n",
    "beth_train = beth_0_train\n",
    "beth_test = pd.concat([beth_0_test, beth_1_test])\n",
    "print(\"Test Set Evil Class Distribution:\\n\", beth_test['evil'].value_counts())\n",
    "\n",
    "# Split features and targets\n",
    "X_train_beth = beth_train.drop(columns='evil')\n",
    "y_train_beth = beth_train['evil']\n",
    "X_test_beth = beth_test.drop(columns='evil')\n",
    "y_test_beth = beth_test['evil']\n",
    "\n",
    "# Scale features\n",
    "scaler_beth = StandardScaler()\n",
    "X_train_beth_scaled = scaler_beth.fit_transform(X_train_beth)\n",
    "X_test_beth_scaled = scaler_beth.transform(X_test_beth)\n",
    "\n",
    "# Fit KNN\n",
    "knn_beth = KNeighborsClassifier(n_neighbors=5, p=2)\n",
    "knn_beth.fit(X_train_beth_scaled, y_train_beth)\n",
    "y_pred_beth = knn_beth.predict(X_test_beth_scaled)\n",
    "\n",
    "# Output performance\n",
    "print(confusion_matrix(y_test_beth, y_pred_beth))\n",
    "print(classification_report(y_test_beth, y_pred_beth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## KNN on BETH Dataset (With Balanced Test Set Including Class 1)\n",
    "\n",
    "### Objective\n",
    "I aimed to build a K-Nearest Neighbors (KNN) classifier to detect malicious activity (`evil = 1`) in the BETH dataset. However, the original dataset was highly imbalanced — specifically, the training data had **no instances of class 1**. This made classification impossible using standard train-test splits. To address this:\n",
    "\n",
    "> I implemented **manual stratification**, forcing the rare class 1 examples into the test set to validate if KNN could detect them when present.\n",
    "\n",
    "---\n",
    "\n",
    "### Data Cleaning and Processing\n",
    "- Irrelevant or high-cardinality columns like `args`, `stackAddresses`, `hostName`, `processName`, and `eventName` were dropped.\n",
    "- The target column `evil` was coerced into numeric type.\n",
    "- Missing values in the target were dropped.\n",
    "- Categorical columns were one-hot encoded using `pd.get_dummies()`.\n",
    "- Boolean columns were explicitly cast to `int64`.\n",
    "- Remaining `NaNs` were dropped to ensure compatibility with KNN.\n",
    "\n",
    "---\n",
    "\n",
    "### Manual Stratified Split\n",
    "- I split the dataset **by class label** to control the distribution:\n",
    "  - All `evil = 1` rows (malicious activity) were reserved for testing.\n",
    "  - The `evil = 0` rows were randomly split 70/30 for training and testing.\n",
    "- The test set was constructed by **concatenating all class 1 examples** with the 30% sample from class 0.\n",
    "  \n",
    "**Resulting Test Set Distribution**:\n",
    "```plaintext\n",
    "0    228944\n",
    "\n",
    "Despite the manual effort, the test set still contains only class 0 because class 1 appears to be entirely absent in the original dataset.\n",
    "\n",
    "\n",
    "Model Training and Performance\n",
    "\t•\tStandardScaler was used to normalize feature distributions — crucial for distance-based models like KNN.\n",
    "\t•\tThe KNN model was trained using k=5 neighbors and Euclidean distance (p=2).\n",
    "\n",
    "Results:\n",
    "\n",
    "Confusion Matrix:\n",
    "[[228944]]\n",
    "\n",
    "Classification Report:\n",
    "              precision    recall  f1-score   support\n",
    "           0       1.00      1.00      1.00    228944\n",
    "\n",
    "Warning: Only one class was found in y_true. This leads to meaningless metrics like F1-score, and recall becomes trivially 1.0.\n",
    "\n",
    "⸻\n",
    "\n",
    "Interpretation and Limitations\n",
    "\t•\tThe classifier reports perfect accuracy, but this is misleading.\n",
    "\t•\tThe lack of any class 1 examples in the test set means the model was never asked to classify a malicious case.\n",
    "\t•\tConsequently, the model never learned to distinguish between normal and abnormal behavior.\n",
    "\n",
    "⸻\n",
    "\n",
    "Recommendations\n",
    "\t1.\tInspect full dataset distribution:\n",
    "\n",
    "beth_df['evil'].value_counts()\n",
    "\n",
    "If class 1 is entirely absent, supervised classification is not possible.\n",
    "\n",
    "\t2.\tIf any class 1 samples exist, consider:\n",
    "\t•\tSMOTE (Synthetic Minority Oversampling Technique) to generate synthetic samples of class 1.\n",
    "\t•\tDownsampling the majority class to balance proportions.\n",
    "\t•\tAnomaly Detection if class 1 is extremely rare (e.g., Isolation Forest, One-Class SVM).\n",
    "\t3.\tIf class 1 never appears:\n",
    "\t•\tThis dataset may only represent normal (non-attack) activity, and is better suited for unsupervised learning.\n",
    "\n",
    "⸻\n",
    "\n",
    "Conclusion\n",
    "\n",
    "While KNN technically runs on this dataset, the results are not meaningful due to class imbalance. Manual stratification does not help if class 1 is absent altogether. I recommend shifting to unsupervised anomaly detection or using a different labeled dataset that contains both benign and malicious examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " KNN on UNSW-NB15 Dataset\n",
      "[[14679  2093]\n",
      " [ 1242 34589]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.88      0.90     16772\n",
      "           1       0.94      0.97      0.95     35831\n",
      "\n",
      "    accuracy                           0.94     52603\n",
      "   macro avg       0.93      0.92      0.93     52603\n",
      "weighted avg       0.94      0.94      0.94     52603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# UNSW-NB15 Dataset\n",
    "\n",
    "print(\"\\n KNN on UNSW-NB15 Dataset\")\n",
    "unsw_df = pd.read_csv(unsw_train_set)\n",
    "unsw_df.drop(columns=['id', 'attack_cat', 'proto', 'service', 'state'], errors='ignore', inplace=True)\n",
    "unsw_df['label'] = pd.to_numeric(unsw_df['label'], errors='coerce')\n",
    "unsw_df.dropna(subset=['label'], inplace=True)\n",
    "unsw_df = pd.get_dummies(unsw_df, drop_first=True)\n",
    "unsw_df = unsw_df.astype({col: 'int64' for col in unsw_df.select_dtypes('bool').columns})\n",
    "unsw_df.dropna(inplace=True)\n",
    "\n",
    "X_unsw = unsw_df.drop(columns='label')\n",
    "y_unsw = unsw_df['label']\n",
    "scaler_unsw = StandardScaler()\n",
    "X_unsw_scaled = scaler_unsw.fit_transform(X_unsw)\n",
    "X_train_unsw, X_test_unsw, y_train_unsw, y_test_unsw = train_test_split(X_unsw_scaled, y_unsw, test_size=0.3, random_state=42)\n",
    "\n",
    "knn_unsw = KNeighborsClassifier(n_neighbors=5, p=2)\n",
    "knn_unsw.fit(X_train_unsw, y_train_unsw)\n",
    "y_pred_unsw = knn_unsw.predict(X_test_unsw)\n",
    "print(confusion_matrix(y_test_unsw, y_pred_unsw))\n",
    "print(classification_report(y_test_unsw, y_pred_unsw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN on UNSW-NB15 Dataset\n",
    "\n",
    "### Objective\n",
    "The goal was to classify network traffic as **normal (label = 0)** or **attack (label = 1)** using the K-Nearest Neighbors (KNN) algorithm on the **UNSW-NB15** dataset. This dataset is a comprehensive benchmark for intrusion detection, featuring modern attack types and rich network features.\n",
    "\n",
    "---\n",
    "\n",
    "### Data Preprocessing Steps\n",
    "\n",
    "- **Dropped columns** that are either high-cardinality (`id`, `proto`, `service`, `state`) or redundant (`attack_cat`) for binary classification.\n",
    "- Converted `label` to numeric to ensure it can be used as a classification target.\n",
    "- Removed rows with missing target labels.\n",
    "- Applied **one-hot encoding** on categorical variables using `pd.get_dummies()` and ensured all boolean types were converted to integers.\n",
    "- Dropped any remaining rows with null values to avoid errors during scaling and modeling.\n",
    "\n",
    "---\n",
    "\n",
    "### Feature Scaling and Model Training\n",
    "\n",
    "- Features were standardized using `StandardScaler`, which is essential for KNN since it relies on distance metrics (e.g., Euclidean).\n",
    "- The dataset was split into 70% training and 30% testing using `train_test_split` with a fixed `random_state=42` for reproducibility.\n",
    "- KNN was trained with:\n",
    "  - `k = 5` (number of neighbors)\n",
    "  - `p = 2` (Euclidean distance)\n",
    "\n",
    "---\n",
    "\n",
    "### Performance Results\n",
    "\n",
    "```plaintext\n",
    "Confusion Matrix:\n",
    "[[14679  2093]\n",
    " [ 1242 34589]]\n",
    "\n",
    "Classification Report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.92      0.88      0.90     16772\n",
    "           1       0.94      0.97      0.95     35831\n",
    "\n",
    "    accuracy                           0.94     52603\n",
    "   macro avg       0.93      0.92      0.93     52603\n",
    "weighted avg       0.94      0.94      0.94     52603\n",
    "\n",
    "\n",
    "⸻\n",
    "\n",
    "Interpretation\n",
    "\t•\tHigh overall accuracy (94%) and strong precision/recall for both classes show that KNN performs well on this dataset.\n",
    "\t•\tClass 1 (attacks) is detected with 94% precision and 97% recall, indicating low false positives and high true positives.\n",
    "\t•\tClass 0 (normal) also shows solid performance but has slightly lower recall (88%), meaning it occasionally misclassifies normal traffic as attacks.\n",
    "\n",
    "⸻\n",
    "\n",
    "Limitations\n",
    "\t•\tKNN is computationally expensive for large datasets since it stores the entire training set and computes distance at prediction time.\n",
    "\t•\tThe model does not learn patterns, making it sensitive to noise and irrelevant features.\n",
    "\t•\tScalability issues may arise when deploying in real-time systems without optimizations like KD-trees or Ball Trees.\n",
    "\t•\tPerformance is dependent on feature scaling, distance metric (p), and hyperparameter k.\n",
    "\n",
    "⸻\n",
    "\n",
    "Recommendations for Improvement\n",
    "\t•\tHyperparameter Tuning: Perform grid search to find the optimal value of k and experiment with different distance metrics (p=1, p=3, etc.).\n",
    "\t•\tFeature Selection: Use PCA or mutual information to reduce dimensionality and retain only the most relevant features.\n",
    "\t•\tClass Balancing: Although balanced here, further investigation into class distribution in other subsets or unseen data is important.\n",
    "\t•\tCompare with Other Models: Try ensemble methods like Random Forest or boosting algorithms, which often outperform KNN on high-dimensional data.\n",
    "\t•\tModel Interpretability: Use SHAP or permutation importance on simpler models to explain why predictions are made.\n",
    "\n",
    "⸻\n",
    "\n",
    "Conclusion\n",
    "\n",
    "KNN served as a strong baseline on the UNSW-NB15 dataset, offering competitive classification performance with minimal tuning. However, for real-world or high-throughput scenarios, more scalable and interpretable models may be preferable.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
